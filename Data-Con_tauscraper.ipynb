{
 "metadata": {
  "name": "",
  "signature": "sha256:8144653f5113b5f4aad99dab437ba5c077d6ee1e21fa04a364d4e6660434e889"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##DataTau scraper\n",
      "\n",
      "This ended up to be a fully functional scraper for the popular data links aggregator, datatau.com\n",
      "\n",
      "###First, our usual checks. \n",
      "API? Noooo. \n",
      "\n",
      "Terms of service? Not so much. So, we're cleared for scrape-off.   \n",
      "(lollolololol. that is really bad.)\n",
      "\n",
      "###So let's walk through the scraper."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "sys.path.append('./datatau_scraper')\n",
      "\n",
      "import tauscraper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###You can check out all of this code in datatau_scraper/tauscraper.py\n",
      "\n",
      "We make a `TauCollection` object, which is the class that does most of the stuff. tauscraper also has an `TauItem` class, which we'll get to later."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collection = tauscraper.TauCollection()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###After instantiating the collection,\n",
      "\n",
      "You can run the entire scraper using `collection.scrape_datatau()`\n",
      "You end up with a collection object full of tasty data (which you can explore below if you're running this notebook interactively), and it also archives two .pkl files (one with a dictionary of data, and one that collects the raw html). \n",
      "\n",
      "####Oops, TODO: \n",
      "Just realized that the point of the raw html collection was in case the scrapers fail, the old data will still be available (like I recommended to someone in the Q&A). However, this will not do that, because I forgot to. I'm very sure that everything (dictionary and raw storage) will succeed, or it will all just fail. Let's call this \"to-be-implemented\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collection = collection.scrape_datatau()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded tau item dict from pickle\n",
        "loaded raw pages dict from pickle\n",
        "filling the queue\n",
        "next url:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.datatau.com/x?fnid=OYP8OB3ZBO\n",
        "next url:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.datatau.com/x?fnid=eqcrBB0iYm\n",
        "next url:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.datatau.com/x?fnid=hLTnH609P8\n",
        "next url:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.datatau.com/x?fnid=PdoBR6bMPV\n",
        "next url:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.datatau.com/x?fnid=JDCdLMyL0P\n",
        "next url:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " http://www.datatau.com/x?fnid=nGhNoDapIw\n",
        "reached end of items"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "soup queue full, queued 7 pages\n",
        "processing page 1\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 4272\n",
        "updating item: 4269\n",
        "updating item: 4262\n",
        "updating item: 4265\n",
        "updating item: 4263\n",
        "updating item: 4229\n",
        "updating item: 4234\n",
        "updating item: 4250\n",
        "updating item: 4231\n",
        "updating item: 4230\n",
        "updating item: 4244\n",
        "updating item: 4198\n",
        "updating item: 4222\n",
        "updating item: 4241\n",
        "updating item: 4210\n",
        "updating item: 4227\n",
        "updating item: 4214\n",
        "updating item: 4237\n",
        "updating item: 4216\n",
        "updating item: 4228\n",
        "updating item: 4246\n",
        "updating item: 4204\n",
        "updating item: 4226\n",
        "updating item: 4225\n",
        "updating item: 4130\n",
        "updating item: 4174\n",
        "updating item: 4181\n",
        "updating item: 4242\n",
        "updating item: 4215\n",
        "processing page 2\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 4200\n",
        "updating item: 4145\n",
        "updating item: 4189\n",
        "updating item: 4167\n",
        "updating item: 4058\n",
        "updating item: 4136\n",
        "updating item: 4171\n",
        "updating item: 4193\n",
        "updating item: 4011\n",
        "updating item: 4027\n",
        "updating item: 4114\n",
        "updating item: 4176\n",
        "updating item: 3997\n",
        "updating item: 4173\n",
        "updating item: 4110\n",
        "updating item: 4085\n",
        "updating item: 4160\n",
        "updating item: 4006\n",
        "updating item: 4057\n",
        "updating item: 4097\n",
        "updating item: 4111\n",
        "updating item: 4053\n",
        "updating item: 4146\n",
        "updating item: 4082\n",
        "updating item: 4132\n",
        "updating item: 4152\n",
        "updating item: 3978\n",
        "updating item: 4099\n",
        "updating item: 4028\n",
        "updating item: 4157\n",
        "processing page 3\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 4056\n",
        "updating item: 4108\n",
        "updating item: 3976\n",
        "updating item: 4054\n",
        "updating item: 3988\n",
        "updating item: 4076\n",
        "updating item: 4013\n",
        "updating item: 4025\n",
        "updating item: 4065\n",
        "updating item: 4060\n",
        "updating item: 4003\n",
        "updating item: 4015\n",
        "updating item: 4000\n",
        "updating item: 4109\n",
        "updating item: 4104\n",
        "updating item: 3985\n",
        "updating item: 4098\n",
        "updating item: 4091\n",
        "updating item: 4021\n",
        "updating item: 4080\n",
        "updating item: 4078\n",
        "updating item: 4074\n",
        "updating item: 4069\n",
        "updating item: 3995\n",
        "updating item: 4039\n",
        "updating item: 3987\n",
        "updating item: 3996\n",
        "updating item: 4024\n",
        "updating item: 3989\n",
        "updating item: 3958\n",
        "processing page 4\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 3964\n",
        "updating item: 3830\n",
        "updating item: 3999\n",
        "updating item: 3950\n",
        "updating item: 3891\n",
        "updating item: 3959\n",
        "updating item: 3769\n",
        "updating item: 3715\n",
        "updating item: 3913\n",
        "updating item: 3775\n",
        "updating item: 4018\n",
        "updating item: 3972\n",
        "updating item: 3848\n",
        "updating item: 3949\n",
        "updating item: 3945\n",
        "updating item:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3915\n",
        "updating item: 3914\n",
        "updating item: 3956\n",
        "updating item: 3990\n",
        "updating item: 3935\n",
        "updating item: 3967\n",
        "updating item: 3951\n",
        "updating item: 3966\n",
        "updating item: 3760\n",
        "updating item: 3674\n",
        "updating item: 3955\n",
        "updating item: 3928\n",
        "updating item: 3810\n",
        "updating item: 3753\n",
        "updating item: 3655\n",
        "processing page 5\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 3816\n",
        "updating item: 3920\n",
        "updating item: 3755\n",
        "updating item: 3905\n",
        "updating item: 3875\n",
        "updating item: 3929\n",
        "updating item: 3892\n",
        "updating item: 3953\n",
        "updating item: 3806\n",
        "updating item: 3665\n",
        "updating item: 3783\n",
        "updating item: 3677\n",
        "updating item: 3839\n",
        "updating item: 3944\n",
        "updating item: 3731\n",
        "updating item: 3937\n",
        "updating item: 3858\n",
        "updating item: 3896\n",
        "updating item: 3730\n",
        "updating item: 3704\n",
        "updating item: 3957\n",
        "updating item: 3801\n",
        "updating item: 3916\n",
        "updating item: 3735\n",
        "updating item: 3936\n",
        "updating item: 3825\n",
        "updating item: 3917\n",
        "updating item: 3822\n",
        "updating item: 3853\n",
        "updating item: 3836\n",
        "processing page 6\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 3909\n",
        "updating item: 3834\n",
        "updating item: 3827\n",
        "updating item: 3851\n",
        "updating item: 3847\n",
        "updating item: 3826\n",
        "updating item: 3787\n",
        "updating item: 3299\n",
        "updating item: 3897\n",
        "updating item: 3767\n",
        "updating item: 3837\n",
        "updating item: 3873\n",
        "updating item: 3763\n",
        "updating item: 3809\n",
        "updating item: 3777\n",
        "updating item: 3800\n",
        "updating item: 3786\n",
        "updating item: 3743\n",
        "updating item: 3736\n",
        "updating item: 3805\n",
        "updating item: 3798\n",
        "updating item: 3794\n",
        "updating item: 3686\n",
        "updating item: 3632\n",
        "updating item: 3797\n",
        "updating item: 3814\n",
        "updating item: 3813\n",
        "updating item: 3696\n",
        "updating item: 3707\n",
        "updating item: 3739\n",
        "processing page 7\n",
        "soup to rows\n",
        "rows to items\n",
        "processing items\n",
        "updating item: 3762\n",
        "updating item: 3729\n",
        "updating item: 3716\n",
        "updating item: 3648\n",
        "updating item: 3776\n",
        "updating item: 3772\n",
        "updating item: 3721\n",
        "updating item: 3756\n",
        "updating item: 3645\n",
        "updating item: 3732\n",
        "updating item: 3741\n",
        "updating item: 3695\n",
        "updating item: 3713\n",
        "updating item: 3712\n",
        "updating item: 2940\n",
        "updating item: 3771\n",
        "updating item: 3702\n",
        "updating item: 3592\n",
        "updating item:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3692\n",
        "updating item: 3727\n",
        "updating item: 3689\n",
        "updating item: 3687\n",
        "updating item: 3680\n",
        "updating item: 3643\n",
        "updating item: 3651\n",
        "updating item: 3650\n",
        "updating item: 3626\n",
        "updating item: 3644\n",
        "updating item: 3693\n",
        "updating item: 3590\n",
        "pickling the data\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "collection = collection.load_data_from_pickles()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loaded tau item dict from pickle\n",
        "loaded raw pages dict from pickle\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#collection.tau_dict\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "7"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "\n",
      "with open('tau_item_dict.pkl','rb') as infile:\n",
      "    tau_data = pickle.load(infile)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(tau_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "210"
       ]
      }
     ],
     "prompt_number": 5
    }
   ],
   "metadata": {}
  }
 ]
}